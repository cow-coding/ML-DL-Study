{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.LossFunction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1mwdf2BXCWQ5kb2yRaUz0eU3pjGFyzkvC",
      "authorship_tag": "ABX9TyPzwTUhCfRx2T4Bby98yFeT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cow-coding/ML-DL-Study/blob/master/DL%20from%20Scratch/Book%201/Chap04/1.LossFunction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yGEyrwRB1r6"
      },
      "source": [
        "# Drive Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxrbCIFSB3pP",
        "outputId": "08bb2d4c-a9f6-45c3-ae24-7b07d6142643"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tyVt3w55MbF"
      },
      "source": [
        "# Library Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k41mFfsn5MGf"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf1uSBXF0E3l"
      },
      "source": [
        "# Loss Function\n",
        "\n",
        "- 신경망은 '하나의 지표'를 기준으로 최적의 매개변수 값을 탐색한다.  \n",
        "이때 사용하는 지료가 **손실 함수(loog function)**이다.  \n",
        "일반적으로 손실함수는 통계학에서 사용하는 회귀분석에 자주 나타는 **평균 제곱 오차(Mean Squared Error, MSE)**  \n",
        "와 **교차 엔트로피 오차(Cross Entropy Error, CEE)**를 사용한다.  \n",
        "\n",
        "- 손실 함수는 간단하게 말하면 신경망 성능의 '나쁨'을 나타내는 지표이다.  \n",
        "즉, 훈련 데이터를 얼마나 잘 처리하지 '못'하냐를 나타낸다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EknPc3p_1evS"
      },
      "source": [
        "## Mean Squared Error (MSE)\n",
        "\n",
        "최소 제곱 오차 (Mean Squared Error, MSE)는 손실 함수에서 가장 많이 쓰인다.  \n",
        "\n",
        "$$\n",
        "MSE = \\frac{1}{2}\\sum_{k} (y_{k}-t_{k})^{2}\n",
        "$$  \n",
        "\n",
        "- $y_{k}$ : 신경망의 출력(추정값)\n",
        "- $t_{k}$ : 정답 label (one-hot encoding)\n",
        "- $k$ : 데이터의 차원  \n",
        "\n",
        "이해를 돕기위해 아래의 간단한 예시를 보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqHL4p023maN"
      },
      "source": [
        "### Simple example of MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXq8DyEWybEs"
      },
      "source": [
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZsR3Ayd35Np"
      },
      "source": [
        "여기서 `y`는 softmax를 통해 나온 출력값이다.  \n",
        "t는 원-핫 인코딩을 통해 찾은 정답 인덱스 표시값이다.  \n",
        "이제 MSE를 구현하는 함수를 만들어 보자."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS7ZhK3p4a91"
      },
      "source": [
        "#### Implementation of MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKOQ4zc24Eqk"
      },
      "source": [
        "def MSE(y, t):\n",
        "  return 0.5 * np.sum((y - t) ** 2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_wD9QuA4jnq",
        "outputId": "73786251-26ef-4b71-ac98-630f9c1abe42"
      },
      "source": [
        "# ex1 : predict '2' is high percentage\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "print(MSE(np.array(y), np.array(t)))\n",
        "\n",
        "# ex2 : predict '7' is high percentage\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print(MSE(np.array(y), np.array(t)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09750000000000003\n",
            "0.5975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "des8CgYA5T_g"
      },
      "source": [
        "위의 예를 보면 첫번째 예의 손실 함수 출력이 작으며 정답 레이블과 오차가 작다.  \n",
        "결과적으로 MSE 기준으로는 첫 번째 결과가 정답에 더 가까운 것으로 추정한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnGc3-6i5sBQ"
      },
      "source": [
        "## Cross Entropy Error (CEE)\n",
        "\n",
        "$$\n",
        "CEE = -\\sum_{k} (t_{k}\\ln{y_{k}})\n",
        "$$  \n",
        "\n",
        "- $y_{k}$ : 신경망의 출력(추정값)\n",
        "- $t_{k}$ : 정답 label (one-hot encoding)\n",
        "- $k$ : 데이터의 차원  \n",
        "\n",
        "자연로그 연산을 하는 것을 알 수 있다. 결과적으로 모든 값은 양수로 나타난다.  \n",
        "대신에 $t_{k}$는 원-핫 인코딩 값을 갖고 있으므로 정답으로 판정되는 값의 출력이 전체 값을 정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "JhCZPwE08B54",
        "outputId": "41e5459a-9dc1-489b-9c15-71a27ee35372"
      },
      "source": [
        "# 자연로그 그래프 그리는 코드\n",
        "# X값 생성\n",
        "x = np.linspace(start=0.0, stop=1.0, num=1000)\n",
        "\n",
        "plt.figure(figsize=(10, 6)) # 크기 지정\n",
        "\n",
        "# 자연로그(Natural Logarithm) Y값 생성 \n",
        "plt.plot(x, np.log(x), 'b-', label='Natural Logarithm(ln)')\n",
        "plt.legend()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f330bf5c310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muHJ2qJW8TpJ"
      },
      "source": [
        "자연로그 그래프를 보면 x가 1이면 y가 0이되고 x가 0에 가까울수록 y는 점점 작아진다.  \n",
        "결과적으로 CEE의 식을 보면 출력값이 커질수록 0에 가까워지다가, 출력이 1이되면 값이 0이된다.  \n",
        "즉 결과적으로 정답일 확률이 낮아질수록 오차값이 커진다. (물론 원-핫 인코딩이라 0 아니면 1이다.)  \n",
        "= 오차값이 크다 -> 정답일 확률이 낮다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck4Ov9MT9W_N"
      },
      "source": [
        "### Simple example of CEE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMEWP4y996hH"
      },
      "source": [
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agz6E5PB9cjt"
      },
      "source": [
        "#### Implementation of CEE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dILh9OfY8cB6"
      },
      "source": [
        "def CEE(y, t):\n",
        "  delta = 1e-7 # np.log에 0이 들어가서 -inf로 연산이 불가능하게 되는 것을 막기위함\n",
        "  \n",
        "  return -np.sum(t * np.log(y + delta))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg856_3W9qX1",
        "outputId": "a34d1ac3-3cd5-4a46-c1b3-eb4af1de8960"
      },
      "source": [
        "# ex1 : predict '2' is high percentage\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "print(CEE(np.array(y), np.array(t)))\n",
        "\n",
        "# ex2 : predict '7' is high percentage\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print(CEE(np.array(y), np.array(t)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.510825457099338\n",
            "2.302584092994546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mibhz3mI-VU2"
      },
      "source": [
        "위의 예로 CEE를 계산하면 아래와 같다.  \n",
        "첫 번째 예시의 $t_{k}\\ln{y_{k}}$를 계산하면 1 * ln(0.6) = 약 0.51이다.  \n",
        "두 번째 예시의 $t_{k}\\ln{y_{k}}$를 계산하면 1 * ln(0.1) = 약 2.3이다.  \n",
        "즉 계산결과(오차)가 더 작은 첫 번째 추정이 정답일 가능성이 높다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-UNo7Jz_2nj"
      },
      "source": [
        "# Mini Batch Learning\n",
        "\n",
        "훈련 데이터를 통해 손실 함수가 가장 작아지는 매개변수를 찾아야한다.  \n",
        "결국 모든 훈련 데이터를 대상으로 손실 함수를 구해야한다. <- 배치 프로세싱  \n",
        "이 경우를 생각해서 CEE를 수정하면 다음과 같다.  \n",
        "\n",
        "$$\n",
        "CEE = -\\frac{1}{N}\\sum_{n} \\sum_{k} (t_{nk}\\ln{y_{nk}})\n",
        "$$  \n",
        "\n",
        "데이터가 N개일때, $t_{nk}$는 n번째 데이터의 k번째 값을 의미한다.  \n",
        "이때 N으로 나누는 이유는 정규화 작업을 진행하는 것이다. ('평균 손실 함수')  \n",
        "\n",
        "하지만 이 식을 실제로 구현하면 이중 for문의 형태가 나타나는데, 시간복잡도가 $O(n^2)$이 되므로 데이터 값이 커질수록 시간 효율은 극악이 된다.  \n",
        "\n",
        "이를 해결하는 방법이 데이터의 일부만 추려서 '근사치'를 활용하는 **미니배치(mini-batch)**를 사용한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1doTFmLHC84Y"
      },
      "source": [
        "## Mini batch with MNIST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT_6FrEPDig-"
      },
      "source": [
        "### Load MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmSxTVru-C-p",
        "outputId": "a89092e7-4ffd-4b99-f30d-a5d4a7f80099"
      },
      "source": [
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MysPfZdaDl5_"
      },
      "source": [
        "### Extract random data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9IQT7q6DWcs"
      },
      "source": [
        "train_size = x_train.shape[0]\n",
        "# extraction size\n",
        "batch_size = 10 \n",
        "# choice is random extract function\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q-DvfsOE_vg"
      },
      "source": [
        "### Implementation CEE for mini batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdALujukEElE"
      },
      "source": [
        "# 이 부분은 다시 잘 이해해보기\n",
        "def CEE(y, t, one_hot=True):\n",
        "  if one_hot:\n",
        "    # one-hot encoding data\n",
        "    if y.ndim == 1:\n",
        "      t = t.reshape(t, t.size)\n",
        "      y = y.reshape(y, y.size)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "\n",
        "    return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
        "\n",
        "  else:\n",
        "    if y.ndim == 1:\n",
        "      t = t.reshape(t, t.size)\n",
        "      y = y.reshape(y, y.size)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1LUb33mLMKZ"
      },
      "source": [
        "# Why use loss function?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgRsU-3_LSER"
      },
      "source": [
        "이쯤되면 왜 귀찮고 이해하기 어렵게 손실함수를 사용하는 지가 생각이 든다.  \n",
        "사실 직관적이고 바로바로 알아볼 수 있게 '정확도'를 사용하면 안될까?라는 생각도 할 수 있다.  \n",
        "이 질문의 답은 '미분'이 갖는 역할에 주목하면 알 수 있다.  \n",
        "\n",
        "신경망 학습에서 최적의 매개변수를 탐색할 때 손실 함수를 가능한 작게 만드는 매개변수를 찾는다.  \n",
        "이 의미는 수학적으로 바라보면 극소, 최소를 찾는 것이라 볼 수 있다.  \n",
        "이 과정에서 미분이 사용된다.  \n",
        "\n",
        "여기서 미분 값이 음수면 매개변수를 양의 방향으로, 값이 양수면 매개변수를 음의 방향으로 조정한다.  \n",
        "하지만 미분 값이 0이라면 어떠한 조정도 이루어지지 않는다.  \n",
        "\n",
        "그렇다면 이게 왜 정확도를 쓸 수 없는가?의 답인 걸까?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94DGCyXxNeRg"
      },
      "source": [
        "## Why can't we use accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_KLqpgkNlfH"
      },
      "source": [
        "'정확도'를 지표로 삼게되면 매개변수의 미분 값이 대대분의 지점에서 0이 된다.  \n",
        "왜 '정확도'는 대부분의 미분 값이 0이될까?  \n",
        "\n",
        "예를 들어 생각해보자. 100장의 이미지 중에 32장이 올바르게 인식했다고 하자.  \n",
        "이때의 정확도는 32%가 된다.  \n",
        "만약 정확도를 사용해서 수치를 조정해도 정확하게 33장이 올바르게 인식되지 않는다면 계속해서 32%의 정확도를 갖는다.  \n",
        "그리고 개선이 된다고 해도 33%, 34%처럼 **부드러운**형태가 아닌 불연속적인 변화가 나타나는 **계단함수**가 된다.  \n",
        "\n",
        "즉 매개변수의 미세한 변화가 주는 변화를 계단 함수는 무효화시켜 버리기 때문에 손실 함수에는 변화가 나타나지 않는다.  \n",
        "\n",
        "하지만 시그모이드 형태의 함수는 지속적인 변화가 나타나고 어떤 부분에서도 0의 미분값이 나타나지 않는다.  \n",
        "이런 이유로 '정확도'가 아닌 '손실함수'를 사용하는 것이다."
      ]
    }
  ]
}